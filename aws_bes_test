#!/bin/sh
# set -x 

HYRAX="http://t41m1.opendap.org:8080/opendap"
RESULTS_DIR="./aws_bes_test_201908011309.results"


DAP2_CE_AIRS_ONE_VAR="ClrOLR_A[0:1:179][0:1:359]"
DAP2_CE_AIRS_ONE_VAR_AGG="ClrOLR_A[0:1:364][0:1:179][0:1:359]"

DAP2_VAR_SIZE_ONE_DAY=259343
DAP2_VAR_SIZE_ONE_YEAR=94608110


AIRS_DMRPP_AGG_CHUNKS_TXT="airs_agg_clr_olr_chunks.txt"
AIRS_DMRPP_AGG_FILES="airs_dmrpp_agg_files"

REQUEST_FINISHED_BOUNDARY="### - - - - - - - - - - - - - - - - - - - - - - - -";
HALF_MARK="----------------------------------------------------------------------"

date_cmd="date -Ins"
date_cmd="date"

#####################################################################################
#
# show_test_reps()
#
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function show_test_reps(){
    echo "bess_airs_dmrpp_datasets           TotalReps: ${bess_airs_dmrpp_datasets_REPS}";
    echo "bess_airs_onevar_dmrpp_agg         TotalReps: ${bess_airs_onevar_dmrpp_agg_REPS}";
    echo "curl_range_get_airs_onevar_chunks  TotalReps: ${curl_range_get_airs_onevar_chunks_REPS}";
    echo "hyrax_airs_dmrpp_dataset_file      TotalReps: ${hyrax_airs_dmrpp_dataset_files_REPS}";
    echo "hyrax_airs_onevar_dmrpp_agg        TotalReps: ${hyrax_airs_onevar_dmrpp_agg_REPS}";
}

#####################################################################################
#
# show_elapsed()
#
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function show_elapsed() {
    echo "bess_airs_dmrpp_datasets           elapsed: ${badd_ELAPSED} seconds" 
    echo "bess_airs_onevar_dmrpp_agg         elapsed: ${baoda_ELAPSED} seconds" 
    echo "curl_range_get_airs_onevar_chunks  elapsed: ${crgaoc_ELAPSED} seconds" 
    echo "hyrax_airs_dmrpp_dataset_file      elpased: ${haddf_ELAPSED} seconds"
    echo "hyrax_airs_onevar_dmrpp_agg        elpased: ${haoda_ELAPSED} seconds" 
}


#####################################################################################
#
# echo_elapsed_setters()
#
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function echo_elapsed_setters() {
    echo "badd_ELAPSED=${badd_ELAPSED}" 
    echo "baoda_ELAPSED=${baoda_ELAPSED}" 
    echo "crgaoc_ELAPSED=${crgaoc_ELAPSED}" 
    echo "haddf_ELAPSED=${haddf_ELAPSED}" 
    echo "haoda_ELAPSED=${haoda_ELAPSED}" 
}


#####################################################################################
#
# set_test_reps()
#
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function set_test_reps_by_time_balance(){
    echo "${HALF_MARK}"
    scale_factor="${1}";
    if [ -z ${scale_factor} ]
    then 
        echo "scale_factor was not set! Using a value of 1." 
        scale_factor=1;
    # else 
        # echo "scale_factor is set to '${scale_factor}'"; 
    fi
    

    echo "set_test_reps_by_time_balance() - BEGIN (scale_factor: ${scale_factor})"
    
    echo "Elapsed times:"
    show_elapsed
    echo "#   +    +    +    +    +    +    +    +    +    +    +    +    +"
    
    let max_time="${haoda_ELAPSED}"
    for elapsed_time_val in ${haddf_ELAPSED} ${haoda_ELAPSED} ${badd_ELAPSED} ${baoda_ELAPSED} ${crgaoc_ELAPSED};
    do
        let time="${elapsed_time_val}"
        #echo "This time is ${time} seconds"
        if [ ${max_time} -lt ${time} ]
        then
            let max_time=${time};
        fi
        #echo "Max time is ${max_time} seconds"
    done
    
    echo "Max rep time was ${max_time} seconds"
    
    bess_airs_dmrpp_datasets_REPS=`echo "${scale_factor}*${max_time}/${badd_ELAPSED}" | bc`
    bess_airs_onevar_dmrpp_agg_REPS=`echo "${scale_factor}*${max_time}/${baoda_ELAPSED}" | bc`
    curl_range_get_airs_onevar_chunks_REPS=`echo "${scale_factor}*${max_time}/${crgaoc_ELAPSED}" | bc`
    hyrax_airs_dmrpp_dataset_files_REPS=`echo "${scale_factor}*${max_time}/${haddf_ELAPSED}" | bc`
    hyrax_airs_onevar_dmrpp_agg_REPS=`echo "${scale_factor}*${max_time}/${haoda_ELAPSED}" | bc`
    
    echo "#   +    +    +    +    +    +    +    +    +    +    +    +    +"
    echo "Time balanced Test Reps"
    show_test_reps
    echo "${HALF_MARK}"

}


    
#####################################################################################
#
# set_test_reps()
#
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function set_test_reps(){
    set_reps_REPS=${1};
    bess_airs_dmrpp_datasets_REPS=${set_reps_REPS}
    bess_airs_onevar_dmrpp_agg_REPS=${set_reps_REPS}
    curl_range_get_airs_onevar_chunks_REPS=${set_reps_REPS}
    hyrax_airs_dmrpp_dataset_files_REPS=${set_reps_REPS}
    hyrax_airs_onevar_dmrpp_agg_REPS=${set_reps_REPS}
    show_test_reps
}


#####################################################################################
#
# make_bes_cmd()
# Builds a BES command using the a HERE document and the values of DATASET and 
# DAP2_CE
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function make_bes_cmd() {
BES_CMD=`cat <<EOF 
<?xml version="1.0" encoding="UTF-8"?>
<bes:request xmlns:bes="http://xml.opendap.org/ns/bes/1.0#" reqID="[thread:http-nio-8080-exec-9-27]">
  <bes:setContext name="xdap_accept">3.2</bes:setContext>
  <bes:setContext name="dap_explicit_containers">no</bes:setContext>
  <bes:setContext name="errors">xml</bes:setContext>
  <bes:setContext name="max_response_size">0</bes:setContext>
  <bes:setContainer name="catalogContainer" space="catalog">${DATASET}</bes:setContainer>
  <bes:define name="d1" space="default">
    <bes:container name="catalogContainer">
      <bes:constraint>${DAP2_CE}</bes:constraint>
    </bes:container>
  </bes:define>
  <bes:get type="dods" definition="d1" />
</bes:request>
EOF
`
}


#####################################################################################
#
# make_and_time_bess_request()
# Updates the BES command using make_bes_cmd() and then times the execution of the 
# command using besstandalone
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function make_and_time_bess_request {
    tag=${1}
    expected_size=${2}
    
    make_bes_cmd
    # echo "BES_CMD: "
    # echo "${BES_CMD}"
    echo "Dataset: ${DATASET}" >> ${timing_file}
    echo "${BES_CMD}" > bes.cmd
    echo "tag: ${tag}"  >> ${timing_file}
    echo "expected_size: ${expected_size}"  >> ${timing_file}
    echo "StartTime: "`${date_cmd}` >> ${timing_file}
    
    { time -p besstandalone -c ${prefix}/etc/bes/bes.conf -i bes.cmd > ${response_file}; } 2>>${timing_file}
    
    response_size=`cat ${response_file} | wc -c`
    echo `basename ${response_file}`" size: ${response_size} bytes"  >> ${timing_file}
    
    if [ -n "${expected_size}" ] && [ ${response_size} -ne ${expected_size} ]
    then
        e_dir=`dirname ${response_file}`
        #echo "e_dir: ${e_dir}"
        e_file=`basename ${response_file}`
        #echo "e_file: ${e_file}"
        e_name="${e_dir}/ERROR_${tag}_${e_file}"
        #echo "e_name: ${e_name}"
        echo "ERROR! Did recieve expected number of bytes. expected: ${expected_size} recieved: ${response_size}" | tee -a ${timing_file}
        echo "Copying response file to ${e_name}" | tee -a ${timing_file}
        cp -v "${response_file}" "${e_name}" >> ${timing_file}
    fi

    echo "${REQUEST_FINISHED_BOUNDARY}" >> ${timing_file}
    # getdap -D -M ${response_file} >> ${log_file}
    # exit;
   
}

#####################################################################################
#
# make_and_time_curl_range_get_request()
# Times the execution of a cURL range GET request based on the values of URL,
# CURL_START, and CURL_END
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function make_and_time_curl_range_get_request {
    tag=${1};

    expected_size=`echo ${CURL_END} - ${CURL_START} + 1| bc`
    echo "RangeGET cURL: ${URL} CURL_START: ${CURL_START} CURL_END: ${CURL_END}" >> ${timing_file}
    echo "tag: ${tag}" >> ${timing_file}
    echo "expected_size: ${expected_size}"  >> ${timing_file}
    echo "StartTime: "`${date_cmd}` >> ${timing_file}
    
    { time -p curl -s -r ${CURL_START}-${CURL_END} -g ${URL} > ${response_file}; } 2>>${timing_file}
    
    response_size=`cat ${response_file} | wc -c`
    echo `basename ${response_file}`" size: ${response_size} bytes"  >> ${timing_file}
   
    if [ ${response_size} -ne ${expected_size} ]
    then
        e_dir=`dirname ${response_file}`
        #echo "e_dir: ${e_dir}"
        e_file=`basename ${response_file}`
        #echo "e_file: ${e_file}"
        e_name="${e_dir}/ERROR_${tag}_${e_file}"
        #echo "e_name: ${e_name}"
        echo "ERROR! Did recieve expected number of bytes. expected: ${expected_size} recieved: ${response_size}" | tee -a ${timing_file}
        echo "Copying response file to ${e_name}" | tee -a ${timing_file}
        cp -v "${response_file}" "${e_name}" >> ${timing_file}
    fi
  
    echo "${REQUEST_FINISHED_BOUNDARY}" >> ${timing_file}
}

#####################################################################################
#
# make_and_time_curl_get_request
# Times the execution of a cURL GET request based on the value of URL.
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function make_and_time_curl_get_request {
    tag=${1};
    expected_size=${2};
    
    echo "GET cURL: ${URL}" >> ${timing_file}
    echo "tag: ${tag}"  >> ${timing_file}
    echo "expected_size: ${expected_size}"  >> ${timing_file}
    echo "StartTime: "`${date_cmd}` >> ${timing_file}

    { time -p curl -s -g ${URL} > ${response_file}; } 2>>${timing_file}
    
    # ls -l ${response_file} >> ${timing_file}
    response_size=`cat ${response_file} | wc -c`
    echo `basename ${response_file}`" size: ${response_size} bytes"  >> ${timing_file}
    if [ -n "${expected_size}" ] && [ ${response_size} -ne ${expected_size} ]
    then
        e_dir=`dirname ${response_file}`
        #echo "e_dir: ${e_dir}"
        e_file=`basename ${response_file}`
        #echo "e_file: ${e_file}"
        e_name="${e_dir}/ERROR_${tag}_${e_file}"
        #echo "e_name: ${e_name}"
        echo "ERROR! Did recieve expected number of bytes. expected: ${expected_size} recieved: ${response_size}" | tee -a ${timing_file}
        echo "Copying response file to ${e_name}" | tee -a ${timing_file}
        cp -v "${response_file}" "${e_name}" >> ${timing_file}
    fi
    echo "${REQUEST_FINISHED_BOUNDARY}" >> ${timing_file}
}



#####################################################################################
#
# `hyrax_airs_dmrpp_dataset_files` - This test utilizes command line `curl` to 
# GET the ClrOLR_A variable data response for each of the 365 dmr++ files in the 
# AIRS aggregation. 
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function hyrax_airs_dmrpp_dataset_files(){
    
    log_file="${RESULTS_DIR}/hyrax_airs_dmrpp_dataset_files.log"
    response_file="${RESULTS_DIR}/hyrax_airs_dmrpp_dataset_files.dods"
    timing_file="${RESULTS_DIR}/hyrax_airs_dmrpp_dataset_files.time"

    DAP2_CE="${DAP2_CE_AIRS_ONE_VAR}"
    rm -vfr ${timing_file} ${log_file}
    haddf_START=`date +%s`;

    echo "###----------------------------------------------------------" >> ${timing_file}
    echo -n "### hyrax_airs_dmrpp_dataset_files() - BEGIN " >> ${timing_file}
    echo "reps: ${hyrax_airs_dmrpp_dataset_files_REPS} start: ${haddf_START}" >> ${timing_file}
    
    for rep in `seq ${hyrax_airs_dmrpp_dataset_files_REPS}`
    do
        echo "###--------------------------------------------------------" >> ${timing_file}
        echo "### hyrax_airs_dataset_dmrpp_files() - Starting REP ${rep}" >> ${timing_file}
        let d_num=0;
        for DATASET in `cat ${AIRS_DMRPP_AGG_FILES}`
        do
            URL="${HYRAX}/${DATASET}.dods?${DAP2_CE}"
            make_and_time_curl_get_request "${rep}_${d_num}" ${DAP2_VAR_SIZE_ONE_DAY}
            let d_num++
        done
    done
    haddf_END=`date +%s`;
    haddf_ELAPSED=`echo ${haddf_END} - ${haddf_START} | bc`
    echo -n "### hyrax_airs_dataset_dmrpp_files() - END  " >> ${timing_file}
    echo -n "reps: ${hyrax_airs_dmrpp_dataset_files_REPS} " >> ${timing_file}
    echo "TotalTime: ${haddf_ELAPSED} seconds" >> ${timing_file}

}

#####################################################################################
#
# `hyrax_airs_onevar_dmrpp_agg` - This test utilizes command line `curl` to GET 
# the aggregated ClrOLR_A variable data response from dmr++ aggregation, 
# `dmrpp_agg_test_06.dmrpp`. Each pass gets the full value of the aggregated 
# variable and again, makes the same number of S3 access as the other tests.
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function hyrax_airs_onevar_dmrpp_agg(){
    
    log_file="${RESULTS_DIR}/hyrax_airs_onevar_dmrpp_agg.log"
    response_file="${RESULTS_DIR}/hyrax_airs_onevar_dmrpp_agg.dods"
    timing_file="${RESULTS_DIR}/hyrax_airs_onevar_dmrpp_agg.time"

    DATASET="t41m1/dmrpp_agg_test_06.dmrpp"
    URL="${HYRAX}/${DATASET}.dods?${DAP2_CE_AIRS_ONE_VAR_AGG}"

    rm -vfr ${timing_file} ${log_file}
    haoda_START=`date +%s`;

    echo "###----------------------------------------------------------" >> ${timing_file}
    echo -n "### hyrax_airs_onevar_dmrpp_agg() - BEGIN " >> ${timing_file}
    echo "reps: ${bess_airs_dmrpp_datasets_REPS} start: ${haoda_START}  URL: ${URL}" >> ${timing_file}
    
    for rep in `seq ${hyrax_airs_onevar_dmrpp_agg_REPS}`
    do
        echo "### hyrax_airs_onevar_dmrpp_agg() - Starting REP ${rep}" >> ${timing_file}
        make_and_time_curl_get_request ${rep} ${DAP2_VAR_SIZE_ONE_YEAR}
    done
    haoda_END=`date +%s`;
    haoda_ELAPSED=`echo ${haoda_END} - ${haoda_START} | bc`
    echo -n "### hyrax_airs_onevar_dmrpp_agg() - END  " >> ${timing_file}
    echo -n "reps: ${hyrax_airs_onevar_dmrpp_agg_REPS} " >> ${timing_file}
    echo "TotalTime: ${haoda_ELAPSED} seconds" >> ${timing_file}
}

#####################################################################################
#
# `bess_airs_dmrpp_datasets` - This test utilizes `besstandalone` requests to 
# retrieve the ClrOLR_A variable from each of the 365 dmr++ datasets for the 
# aggregated AIRS virtual dataset. Each pass represents the same number of S3 
# accesses as requesting the aggregated ClrOLR_A from an NcML aggregation or from 
# a dmr++ aggregation.
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function bess_airs_dmrpp_datasets(){
    
    log_file="${RESULTS_DIR}/bess_airs_dmrpp_datasets.log"
    response_file="${RESULTS_DIR}/bess_airs_dmrpp_datasets.dods"
    timing_file="${RESULTS_DIR}/bess_airs_dmrpp_datasets.time"

    DAP2_CE="${DAP2_CE_AIRS_ONE_VAR}"
    rm -vfr ${timing_file} ${log_file}
    badd_START=`date +%s`;
    
    echo "###----------------------------------------------------------" >> ${timing_file}
    echo -n "### bess_airs_dmrpp_datasets() - BEGIN " >> ${timing_file}
    echo "reps: ${bess_airs_dmrpp_datasets_REPS} start: ${badd_START}" >> ${timing_file}
    
    for rep in `seq ${bess_airs_dmrpp_datasets_REPS}`
    do
        echo "###--------------------------------------------------------" >> ${timing_file}
        echo "### bess_airs_datset_dmrpp_files() - Starting REP ${rep}" >> ${timing_file}
        let d_num=0
        for DATASET in `cat ${AIRS_DMRPP_AGG_FILES}`
        do
            make_and_time_bess_request "${rep}_${d_num}" ${DAP2_VAR_SIZE_ONE_DAY}
            let d_num++
        done
    done
    badd_END=`date +%s`;
    badd_ELAPSED=`echo ${badd_END} - ${badd_START} | bc`
    echo -n "### bess_airs_dmrpp_datasets() - END  " >> ${timing_file}
    echo -n "reps: ${bess_airs_dmrpp_datasets_REPS} " >> ${timing_file}
    echo "TotalTime: ${badd_ELAPSED} seconds" >> ${timing_file}
}


#####################################################################################
#
# `bess_airs_onevar_dmrpp_agg` - The test utilizes a single `besstandalone` 
# request to retieve the entire (365 aggregated time points) data value for the 
# ClrOLR_A variable from the dmr++ aggregation `dmrpp_agg_test_06.dmrpp`. Each 
# pass/rep/count values represents a single request for the aggregated ClrOLR_A 
# value which will have the same number of S3 accesses as the same request put to 
# the NcML aggregation of dmr++ file and as each pass in the first test, 
# `bess_airs_dmrpp_datasets`. 
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function bess_airs_onevar_dmrpp_agg() {

    log_file="${RESULTS_DIR}/bess_airs_onevar_dmrpp_agg.log"
    response_file="${RESULTS_DIR}/bess_airs_onevar_dmrpp_agg.dods"
    timing_file="${RESULTS_DIR}/bess_airs_onevar_dmrpp_agg.time"

    DATASET="t41m1/dmrpp_agg_test_06.dmrpp"
    DAP2_CE="${DAP2_CE_AIRS_ONE_VAR_AGG}"
    
    rm -vfr ${timing_file} ${log_file}
    baoda_START=`date +%s`;

    echo "###----------------------------------------------------------" >> ${timing_file}
    echo -n "### bess_airs_onevar_dmrpp_agg() - BEGIN " >> ${timing_file}
    echo -n "reps: ${bess_airs_onevar_dmrpp_agg} start: ${baoda_START} " >> ${timing_file}
    echo "Dataset: ${DATASET} DAP2_CE: ${DAP2_CE}" >> ${timing_file}
    for rep in `seq ${bess_airs_onevar_dmrpp_agg_REPS}`
    do
        echo "###--------------------------------------------------------" >> ${timing_file}
        echo "### bess_airs_onevar_dmrpp_agg() - Starting REP ${rep}" >> ${timing_file}
        make_and_time_bess_request ${rep} ${DAP2_VAR_SIZE_ONE_YEAR}
    done
    baoda_END=`date +%s`;
    baoda_ELAPSED=`echo ${baoda_END} - ${baoda_START} | bc`
    echo -n "### bess_airs_onevar_dmrpp_agg() - END  " >> ${timing_file}
    echo -n "reps: ${bess_airs_onevar_dmrpp_agg_REPS} " >> ${timing_file}
    echo "TotalTime: ${baoda_ELAPSED} seconds" >> ${timing_file}
}



#####################################################################################
#
# `curl_range_get_airs_onevar_chunks` - This test utilizes command line `curl` 
# and its range GET capability to retreive each chunk of the 365 file aggregated 
# variable ClrOLR_A from the various hdf5 objects held in S3. Each pass retrieves 
# the value of the aggregated variable.
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function curl_range_get_airs_onevar_chunks(){
    
    log_file="${RESULTS_DIR}/curl_range_get_airs_onevar_chunks.log"
    response_file="${RESULTS_DIR}/curl_range_get_airs_onevar_chunks.bin"
    timing_file="${RESULTS_DIR}/curl_range_get_airs_onevar_chunks.time"

    rm -vfr ${timing_file} ${log_file}
    crgaoc_START=`date +%s`;

    echo "###----------------------------------------------------------" >> ${timing_file}
    echo -n "### curl_range_get_airs_onevar_chunks() - BEGIN " >> ${timing_file}
    echo "reps: ${curl_range_get_airs_onevar_chunks_REPS} start: ${crgaoc_START}" >> ${timing_file}
    for rep in `seq ${curl_range_get_airs_onevar_chunks_REPS}`
    do        
        echo "###----------------------------------------------------------" >> ${timing_file}
        echo "### curl_range_get_airs_onevar_chunks() - Starting REP ${rep}" >> ${timing_file}
        let chunk_num=0
        while read chunk_row; do
            
            echo "Processing chunk: ${chunk_row}" >> ${timing_file}
            URL=`echo ${chunk_row} | awk '{print $1;}' -`
            echo "  Chunk URL: ${URL} " >> ${timing_file}

            OFFSET=`echo ${chunk_row} | awk '{print $2;}' -`
            echo "  OFFSET: ${OFFSET} " >> ${timing_file}

            NUM_BYTES=`echo ${chunk_row} | awk '{print $3;}' -`
            echo "  NUM_BYTES: ${NUM_BYTES} " >> ${timing_file}
            
            CHUNK_POSITION=`echo ${chunk_row} | awk '{print $4;}' -`
            echo "  CHUNK_POSITION: ${CHUNK_POSITION} " >> ${timing_file}

            CURL_START=${OFFSET}
            echo "  CURL_START: ${CURL_START} " >> ${timing_file}

            CURL_END=`echo "${OFFSET} + ${NUM_BYTES} - 1" | bc`
            echo "  CURL_END: ${CURL_END}" >> ${timing_file}
            
            make_and_time_curl_range_get_request "${rep}_${chunk_num}" 
            
            let chunk_num++
    
        done <${AIRS_DMRPP_AGG_CHUNKS_TXT}
    done
    crgaoc_END=`date +%s`;
    crgaoc_ELAPSED=`echo ${crgaoc_END} - ${crgaoc_START} | bc`
    echo -n "### curl_range_get_airs_onevar_chunks() - END  " >> ${timing_file}
    echo -n "reps: ${curl_range_get_airs_onevar_chunks_REPS} " >> ${timing_file}
    echo "TotalTime: ${crgaoc_ELAPSED} seconds" >> ${timing_file}
}

#####################################################################################
#
# hr_mark()
# Echos a cheesy ascii "hr" mark to stdout.
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function hr_mark(){
    echo "${HALF_MARK} + ${HALF_MARK}";
}

#####################################################################################
#
# results_summary()
# Echos a simple statistical summary of each of the .time files in the RESULTS_DIR
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function results_summary(){
    hr_mark
    echo "SUMMARY:"
    for timing_file in ${RESULTS_DIR}/*.time
    do 
        test_name=`basename -s ".time" ${timing_file}`
        reps_completed=`grep " END " ${timing_file} | awk '{print $6;}' - `
        total_time=`grep " END " ${timing_file} | awk '{print $8;}' - `

        echo -n "${test_name} "
        echo -n "TotalTime: ${total_time} seconds "
        echo -n "TestReps: ${reps_completed} "
        grep "real" ${timing_file} | awk '\
            {
                sum+=$2+0.0; 
                sumsq+=$2*$2+0.0;
            }
            END{
                avg=sum/NR;
                stdv=sqrt(sumsq/NR - (avg)**2);
                stdvprcnt=100*stdv/avg;
                printf("request_count: %d average_time: %f stdev: %f stdev%: %f\n", 
                NR, avg, stdv, stdvprcnt);
            }' - ;
    done; 
    hr_mark; 
}

#####################################################################################
#
# mk_csv()
# Makes a "timing_file.csv" file for each .time file in the RESULTS_DIR
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function mk_csv(){

    for timing_file in ${RESULTS_DIR}/*.time
    do 
        result_file="${timing_file}.csv"
        basename "${timing_file}" > ${result_file};
        echo "StartTime, ElapsedTime" >> ${result_file};
        #echo "\"StartTime<String>\", \"ElapsedTime<Float32>\"" >> ${result_file};
        awk -v boundaryKey="${REQUEST_FINISHED_BOUNDARY}" \
        'BEGIN{
            startTimeKey="StartTime"; 
            elapsedTimeKey="real"; 
        }
        {
            if(index($0, boundaryKey)==1){
                printf("\"%s\", %s\n", startTime, elapsedTime);
            }
            else {
                if(index($0,startTimeKey)==1){
                    startTime = $2;
                    //gsub(",",".",startTime);
                }              
                if(index($0,elapsedTimeKey)==1){
                    elapsedTime = $2;
                }              
            }
        }' ${timing_file} >> ${result_file}
    done; 
}


#####################################################################################
#
# 
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function run_test_suite(){
    bess_airs_dmrpp_datasets
    bess_airs_onevar_dmrpp_agg
    curl_range_get_airs_onevar_chunks
    hyrax_airs_dmrpp_dataset_files
    hyrax_airs_onevar_dmrpp_agg
}

#####################################################################################
# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
# 
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
hr_mark
echo ${0} - BEGIN 

# Clean results dir
echo "Clearing RESULTS_DIR: ${RESULTS_DIR}"
rm -vfr ${RESULTS_DIR}
# make a new results dir.
mkdir -p ${RESULTS_DIR}

echo ${HALF_MARK}

USER_REPS=30;

if [ -z "${USER_REPS}" ]
then 
    
    set_test_reps 1
    echo ${HALF_MARK}
    
    echo "${0} - Checking Tests for execution times, results will discarded."
    run_test_suite

    set_test_reps_by_time_balance 20
    echo "${0} - Running AWS/BES Tests, results will be saved."
    run_test_suite
else
    set_test_reps ${USER_REPS}
    echo ${HALF_MARK}
    echo "${0} - Running AWS/BES Tests, results will be saved."
    run_test_suite
fi



echo ${HALF_MARK}

# Make the associated CSV files for export.
mk_csv

# Summarize the results
results_summary

echo ${0} - END 
hr_mark
# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
#####################################################################################

     