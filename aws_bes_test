#!/bin/sh
# set -x 

HYRAX="http://t41m1.opendap.org:8080/opendap"
RESULTS_DIR="./aws_bes_test.results"
echo "RESULTS_DIR: ${RESULTS_DIR}"

DAP2_CE_AIRS_ONE_VAR="ClrOLR_A[0:1:179][0:1:359]"
DAP2_CE_AIRS_ONE_VAR_AGG="ClrOLR_A[0:1:364][0:1:179][0:1:359]"

AIRS_DMRPP_AGG_CHUNKS_TXT="airs_agg_clr_olr_chunks.txt"
AIRS_DMRPP_AGG_FILES="airs_dmrpp_agg_files"

REQUEST_FINISHED_BOUNDARY="### - - - - - - - - - - - - - - - - - - - - - - - -";

reps10=10; reps100=100; reps1000=1000;

# reps10=1; reps100=1; reps1000=1;

function show_test_reps(){
    echo "bess_airs_dmrpp_datasets_REPS:          ${bess_airs_dmrpp_datasets_REPS}";
    echo "bess_airs_onevar_dmrpp_agg_REPS:        ${bess_airs_onevar_dmrpp_agg_REPS}";
    echo "curl_range_get_airs_onevar_chunks_REPS: ${curl_range_get_airs_onevar_chunks_REPS}";
    echo "hyrax_airs_dmrpp_dataset_files_REPS:    ${hyrax_airs_dmrpp_dataset_files_REPS}";
    echo "hyrax_airs_onevar_dmrpp_agg_REPS:       ${hyrax_airs_onevar_dmrpp_agg_REPS}";
}


function set_test_reps_by_time_balance(){
    bess_airs_dmrpp_datasets_REPS=${reps10}
    bess_airs_onevar_dmrpp_agg_REPS=${reps1000}
    curl_range_get_airs_onevar_chunks_REPS=${reps100}
    hyrax_airs_dmrpp_dataset_files_REPS=${reps10}
    hyrax_airs_onevar_dmrpp_agg_REPS=${reps1000}
    show_test_reps
}

function set_test_reps(){
    set_reps_REPS=${1};
    bess_airs_dmrpp_datasets_REPS=${set_reps_REPS}
    bess_airs_onevar_dmrpp_agg_REPS=${set_reps_REPS}
    curl_range_get_airs_onevar_chunks_REPS=${set_reps_REPS}
    hyrax_airs_dmrpp_dataset_files_REPS=${set_reps_REPS}
    hyrax_airs_onevar_dmrpp_agg_REPS=${set_reps_REPS}
    show_test_reps
}


#####################################################################################
#
# make_bes_cmd()
# Builds a BES command using the a HERE document and the values of DATASET and 
# DAP2_CE
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function make_bes_cmd() {
BES_CMD=`cat <<EOF 
<?xml version="1.0" encoding="UTF-8"?>
<bes:request xmlns:bes="http://xml.opendap.org/ns/bes/1.0#" reqID="[thread:http-nio-8080-exec-9-27]">
  <bes:setContext name="xdap_accept">3.2</bes:setContext>
  <bes:setContext name="dap_explicit_containers">no</bes:setContext>
  <bes:setContext name="errors">xml</bes:setContext>
  <bes:setContext name="max_response_size">0</bes:setContext>
  <bes:setContainer name="catalogContainer" space="catalog">${DATASET}</bes:setContainer>
  <bes:define name="d1" space="default">
    <bes:container name="catalogContainer">
      <bes:constraint>${DAP2_CE}</bes:constraint>
    </bes:container>
  </bes:define>
  <bes:get type="dods" definition="d1" />
</bes:request>
EOF
`
}


#####################################################################################
#
# make_and_time_bess_request()
# Updates the BES command using make_bes_cmd() and then times the execution of the 
# command using besstandalone
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function make_and_time_bess_request {
    
     make_bes_cmd
    # echo "BES_CMD: "
    # echo "${BES_CMD}"
    echo "Dataset: ${DATASET}" >> ${timing_file}
    echo "${BES_CMD}" > bes.cmd
    echo "StartTime: "`date -Ins` >> ${timing_file}
    # echo "StartTime: "`date` >> ${timing_file}
    { time -p besstandalone -c ${prefix}/etc/bes/bes.conf -i bes.cmd > ${response_file}; } 2>>${timing_file}
    ls -l ${response_file} >> ${timing_file}
    echo "${REQUEST_FINISHED_BOUNDARY}" >> ${timing_file}
    # getdap -D -M ${response_file} >> ${log_file}
    # exit;
   
}

#####################################################################################
#
# make_and_time_curl_range_get_request()
# Times the execution of a cURL range GET request based on the values of URL,
# CURL_START, and CURL_END
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function make_and_time_curl_range_get_request {
    
    echo "RangeGET cURL: ${URL} CURL_START: ${CURL_START} CURL_END: ${CURL_END}" >> ${timing_file}
    echo "StartTime: "`date -Ins` >> ${timing_file}
    # echo "StartTime: "`date` >> ${timing_file}
    { time -p curl -s -r ${CURL_START}-${CURL_END} -g ${URL} > ${response_file}; } 2>>${timing_file}
    ls -l ${response_file} >> ${timing_file}
    echo "${REQUEST_FINISHED_BOUNDARY}" >> ${timing_file}
}

#####################################################################################
#
# make_and_time_curl_get_request
# Times the execution of a cURL GET request based on the value of URL.
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function make_and_time_curl_get_request {
    
    echo "GET cURL: ${URL}" >> ${timing_file}
    echo "StartTime: "`date -Ins` >> ${timing_file}
    # echo "StartTime: "`date` >> ${timing_file}
    { time -p curl -s -g ${URL} > ${response_file}; } 2>>${timing_file}
    ls -l ${response_file} >> ${timing_file}
    echo "${REQUEST_FINISHED_BOUNDARY}" >> ${timing_file}
}



#####################################################################################
#
# `hyrax_airs_dmrpp_dataset_files` - This test utilizes command line `curl` to 
# GET the ClrOLR_A variable data response for each of the 365 dmr++ files in the 
# AIRS aggregation. 
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function hyrax_airs_dmrpp_dataset_files(){
    
    log_file="${RESULTS_DIR}/hyrax_airs_dmrpp_dataset_files.log"
    response_file="${RESULTS_DIR}/hyrax_airs_dmrpp_dataset_files.dods"
    timing_file="${RESULTS_DIR}/hyrax_airs_dmrpp_dataset_files.time"

    DAP2_CE="${DAP2_CE_AIRS_ONE_VAR}"
    

    rm -f ${timing_file} ${log_file}
    haddf_START=`date +%s`;
    for rep in `seq ${hyrax_airs_dmrpp_dataset_files_REPS}`
    do
        echo "###--------------------------------------------------------" >> ${timing_file}
        echo "### hyrax_airs_dataset_dmrpp_files() - Starting REP ${rep}" >> ${timing_file}
        for DATASET in `cat ${AIRS_DMRPP_AGG_FILES}`
        do
            URL="${HYRAX}/${DATASET}.dods?${DAP2_CE}"
            make_and_time_curl_get_request
        done
    done
    haddf_END=`date +%s`;
    haddf_ELPASED=`echo ${haddf_END} - ${haddf_START} | bc`
    echo "### hyrax_airs_dataset_dmrpp_files() - Total Time: ${haddf_ELPASED} seconds" >> ${timing_file}

}

#####################################################################################
#
# `hyrax_airs_onevar_dmrpp_agg` - This test utilizes command line `curl` to GET 
# the aggregated ClrOLR_A variable data response from dmr++ aggregation, 
# `dmrpp_agg_test_06.dmrpp`. Each pass gets the full value of the aggregated 
# variable and again, makes the same number of S3 access as the other tests.
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function hyrax_airs_onevar_dmrpp_agg(){
    
    log_file="${RESULTS_DIR}/hyrax_airs_onevar_dmrpp_agg.log"
    response_file="${RESULTS_DIR}/hyrax_airs_onevar_dmrpp_agg.dods"
    timing_file="${RESULTS_DIR}/hyrax_airs_onevar_dmrpp_agg.time"

    DATASET="t41m1/dmrpp_agg_test_06.dmrpp"
    URL="${HYRAX}/${DATASET}.dods?${DAP2_CE_AIRS_ONE_VAR_AGG}"

    echo "###--------------------------------------------------------" >> ${timing_file}
    echo "hyrax_airs_onevar_dmrpp_agg() URL: ${URL}" >> ${timing_file} >> ${timing_file}

    rm -f ${timing_file} ${log_file}
    haoda_START=`date +%s`;
    for rep in `seq ${hyrax_airs_onevar_dmrpp_agg_REPS}`
    do
        echo "### hyrax_airs_onevar_dmrpp_agg() - Starting REP ${rep}" >> ${timing_file}
        make_and_time_curl_get_request
    done
    haoda_END=`date +%s`;
    haoda_ELPASED=`echo ${haoda_END} - ${haoda_START} | bc`
    echo "### hyrax_airs_onevar_dmrpp_agg() - Total Time: ${haoda_ELPASED} seconds" >> ${timing_file}
}

#####################################################################################
#
# `bess_airs_dmrpp_datasets` - This test utilizes `besstandalone` requests to 
# retrieve the ClrOLR_A variable from each of the 365 dmr++ datasets for the 
# aggregated AIRS virtual dataset. Each pass represents the same number of S3 
# accesses as requesting the aggregated ClrOLR_A from an NcML aggregation or from 
# a dmr++ aggregation.
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function bess_airs_dmrpp_datasets(){
    
    log_file="${RESULTS_DIR}/bess_airs_dmrpp_datasets.log"
    response_file="${RESULTS_DIR}/bess_airs_dmrpp_datasets.dods"
    timing_file="${RESULTS_DIR}/bess_airs_dmrpp_datasets.time"

    DAP2_CE="${DAP2_CE_AIRS_ONE_VAR}"

    rm -f ${timing_file} ${log_file}
    badd_START=`date +%s`;
    for rep in `seq ${bess_airs_dmrpp_datasets_REPS}`
    do
        echo "###--------------------------------------------------------" >> ${timing_file}
        echo "### bess_airs_datset_dmrpp_files() - Starting REP ${rep}" >> ${timing_file}
        for DATASET in `cat ${AIRS_DMRPP_AGG_FILES}`
        do
            make_and_time_bess_request
        done
    done
    badd_END=`date +%s`;
    badd_ELPASED=`echo ${badd_END} - ${badd_START} | bc`
    echo "### bess_airs_dmrpp_datasets() - Total Time: ${badd_ELPASED} seconds" >> ${timing_file}
}


#####################################################################################
#
# `bess_airs_onevar_dmrpp_agg` - The test utilizes a single `besstandalone` 
# request to retieve the entire (365 aggregated time points) data value for the 
# ClrOLR_A variable from the dmr++ aggregation `dmrpp_agg_test_06.dmrpp`. Each 
# pass/rep/count values represents a single request for the aggregated ClrOLR_A 
# value which will have the same number of S3 accesses as the same request put to 
# the NcML aggregation of dmr++ file and as each pass in the first test, 
# `bess_airs_dmrpp_datasets`. 
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function bess_airs_onevar_dmrpp_agg() {

    log_file="${RESULTS_DIR}/bess_airs_onevar_dmrpp_agg.log"
    response_file="${RESULTS_DIR}/bess_airs_onevar_dmrpp_agg.dods"
    timing_file="${RESULTS_DIR}/bess_airs_onevar_dmrpp_agg.time"

    DATASET="t41m1/dmrpp_agg_test_06.dmrpp"
    DAP2_CE="${DAP2_CE_AIRS_ONE_VAR_AGG}"
    
    rm -f ${timing_file} ${log_file}
    baoda_START=`date +%s`;

    echo "###----------------------------------------------------------" >> ${timing_file}
    echo -n "### curl_range_get_airs_onevar_chunks() - BEGIN " >> ${timing_file}
    echo "reps: ${curl_range_get_airs_onevar_chunks_REPS} start: ${crgaoc_START}" >> ${timing_file}
    for rep in `seq ${bess_airs_onevar_dmrpp_agg_REPS}`
    do
        echo "###--------------------------------------------------------" >> ${timing_file}
        echo "### bess_airs_onevar_dmrpp_agg() - Starting REP ${rep}" >> ${timing_file}
        make_and_time_bess_request
    done
    baoda_END=`date +%s`;
    baoda_ELPASED=`echo ${baoda_END} - ${baoda_START} | bc`
    echo "### bess_airs_onevar_dmrpp_agg() - Total Time: ${baoda_ELPASED} seconds" >> ${timing_file}
}



#####################################################################################
#
# `curl_range_get_airs_onevar_chunks` - This test utilizes command line `curl` 
# and its range GET capability to retreive each chunk of the 365 file aggregated 
# variable ClrOLR_A from the various hdf5 objects held in S3. Each pass retrieves 
# the value of the aggregated variable.
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function curl_range_get_airs_onevar_chunks(){
    
    log_file="${RESULTS_DIR}/curl_range_get_airs_onevar_chunks.log"
    response_file="${RESULTS_DIR}/curl_range_get_airs_onevar_chunks.dods"
    timing_file="${RESULTS_DIR}/curl_range_get_airs_onevar_chunks.time"

    rm -f ${timing_file} ${log_file}
    crgaoc_START=`date +%s`;

    echo "###----------------------------------------------------------" >> ${timing_file}
    echo -n "### curl_range_get_airs_onevar_chunks() - BEGIN " >> ${timing_file}
    echo "reps: ${curl_range_get_airs_onevar_chunks_REPS} start: ${crgaoc_START}" >> ${timing_file}
    for rep in `seq ${curl_range_get_airs_onevar_chunks_REPS}`
    do        
        echo "###----------------------------------------------------------" >> ${timing_file}
        echo "### curl_range_get_airs_onevar_chunks() - Starting REP ${rep}" >> ${timing_file}
        while read chunk_row; do
            
            echo "Processing chunk: ${chunk_row}" >> ${timing_file}
            URL=`echo ${chunk_row} | awk '{print $1;}' -`
            echo -n "Chunk URL: ${URL} " >> ${timing_file}

            OFFSET=`echo ${chunk_row} | awk '{print $2;}' -`
            echo -n "OFFSET: ${OFFSET} " >> ${timing_file}

            NUM_BYTES=`echo ${chunk_row} | awk '{print $3;}' -`
            echo -n "NUM_BYTES: ${NUM_BYTES} " >> ${timing_file}
            
            CHUNK_POSITION=`echo ${chunk_row} | awk '{print $4;}' -`
            echo "CHUNK_POSITION: ${CHUNK_POSITION}" >> ${timing_file}

            CURL_START=${OFFSET}
            CURL_END=`echo "${OFFSET} + ${NUM_BYTES} - 1" | bc`
            make_and_time_curl_range_get_request
    
        done <${AIRS_DMRPP_AGG_CHUNKS_TXT}
    done
    crgaoc_END=`date +%s`;
    crgaoc_ELPASED=`echo ${crgaoc_END} - ${crgaoc_START} | bc`
    echo "### curl_range_get_airs_onevar_chunks() - END  end: ${crgaoc_END} TotalTime: ${crgaoc_ELPASED} seconds" >> ${timing_file}
}

#####################################################################################
#
# hr_mark()
# Echos a cheesy ascii "hr" mark to stdout.
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function hr_mark(){
    half_mark="----------------------------------------------------------------------"
    echo "${half_mark} + ${half_mark}";
}

#####################################################################################
#
# results_summary()
# Echos a simple statistical summary of each of the .time files in the RESULTS_DIR
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function results_summary(){
    hr_mark
    echo "SUMMARY:"
    for timing_file in ${RESULTS_DIR}/*.time
    do 
        test_name=`basename -s ".time" ${timing_file}`
        echo -n "test: ${test_name} "
        echo -n "timing_file: ${timing_file} "
        grep "real" ${timing_file} | awk '\
            {
                sum+=$2+0.0; 
                sumsq+=$2*$2+0.0;
            }
            END{
                avg=sum/NR;
                stdv=sqrt(sumsq/NR - (avg)**2);
                stdvprcnt=100*stdv/avg;
                printf("count: %d average: %f stdev: %f stdev%: %f\n", 
                NR, avg, stdv, stdvprcnt);
            }' - ;
    done; 
    hr_mark; 
}

#####################################################################################
#
# mk_csv()
# Makes a "timing_file.csv" file for each .time file in the RESULTS_DIR
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 
function mk_csv(){

    for timing_file in ${RESULTS_DIR}/*.time
    do 
        result_file="${timing_file}.csv"
        echo "${timing_file}" > ${result_file};
        echo "StartTime ElapsedTime" >> ${result_file};
        awk -v boundaryKey="${REQUEST_FINISHED_BOUNDARY}" \
        'BEGIN{
            startTimeKey="Start"; 
            elapsedTimeKey="real"; 
        }
        {
            if(index($0, boundaryKey)==1){
                printf("%s %s\n", startTime, elapsedTime);
            }
            else {
                if(index($0,startTimeKey)==1){
                    startTime = $2;
                }              
                if(index($0,elapsedTimeKey)==1){
                    elapsedTime = $2;
                }              
            }
        }' ${timing_file} >> ${result_file}
    done; 
}

#####################################################################################
# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
# 
#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - 

rm -rf ${RESULTS_DIR}
mkdir -p ${RESULTS_DIR}

# set_reps_by_time_balance

set_test_reps 1

bess_airs_dmrpp_datasets

bess_airs_onevar_dmrpp_agg

curl_range_get_airs_onevar_chunks

hyrax_airs_dmrpp_dataset_files

hyrax_airs_onevar_dmrpp_agg

mk_csv

results_summary

# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
# MMMMMMMMMMMMMMMMMMMMAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIINNNNNNNNNNNNNNNNNNNN ##
#####################################################################################

     